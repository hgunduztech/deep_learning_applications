
#        Deep Learning Türkiye topluluğu tarafından hazırlanmıştır.
        
#            Amaç:IMDB duyularını sınıflandırmak
            
#            Veriseti:KERAS IMDB Data
            
#            ALgoritma:LSTM Convolutional Neural Networks
            
# Hazırlayan:Sinan Kılıç



                                       
from __future__ import print_function

from keras.preprocessing import sequence
from keras.models import Sequential 
from keras.layers import Dense, Dropout, Activation 
from keras.layers import Embedding
from keras.layers import LSTM
from keras.layers import Conv1D, MaxPooling1D
from keras.datasets import imdb

# Embedding
max_features = 20000  #Maximum kelime hafızası sayısı belirledik
maxlen = 100  #Kelimelerin maximum uzunlukları belirledik
embedding_size = 128  #Kelime vektörlerine uygulanacak embedding boyutu belirledik

# Convolution
kernel_size = 5  #Sinir ağımızın çekirdek sayısını belirledik
filters = 64  #Sinir ağımızda vektöre ne kadarlık filtre uygulanacağını belirledik
pool_size = 4  #Verilerden elde ettiğimiz matrisin boyutlandırma miktarını belirledik

# LSTM
lstm_output_size = 70  #LSTM sonucundaki çıktıların boyutlarını belirledik

# Training
batch_size = 30  #Her döngüde kaç veri işleneceğini belirledik
epochs = 2  #Eğitimin kaç adımda gerçekleşeceğini belirledik

'''
Note:
batch_size is highly sensitive.
Only 2 epochs are needed as the dataset is very small.
'''

print('Loading data...')  ##Verisetinin import edildiğini yazdırdık

    #İmport edilen veri setinden eğitim ve test verilerinin belirlenmesi  
(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)
print(len(x_train),)  #Eğitim dizlerinin vektörel uzunluğunu yazdırdık
print(len(x_test), )  #Test dizilerinin vektörel uzunluğunu yazdırdık

    #Pad İşleminin detayları belirledik
print('Pad sequences (samples x time)')
x_train = sequence.pad_sequences(x_train, maxlen=maxlen)
x_test = sequence.pad_sequences(x_test, maxlen=maxlen)
print('x_train shape:', x_train.shape)
print('x_test shape:', x_test.shape)
print('Build model...')

    #Model olarak sıralı model seçtiğimizi belirledik
model = Sequential()

    #Modelimize embedding işlemini ekledik
model.add(Embedding(max_features, embedding_size, input_length=maxlen))

    #Ağ modellemesindeki nöronların % kaçının kapatılacağını belirledik
model.add(Dropout(0.25))
model.add(Conv1D(filters,  #Verileri tek boyutlu olarak işleneceğini belirledik
                 kernel_size,
                 padding='valid',
                 activation='relu',
                 strides=1))
model.add(MaxPooling1D(pool_size=pool_size))  #Verilerden elde edilen matrisi boyutlandırdık
model.add(LSTM(lstm_output_size))  #Modelimize LSTM'i ekledik
model.add(Dense(1))
model.add(Activation('sigmoid'))

model.compile(loss='binary_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

    #Modelin eğitime başladığını yazdırdık
print('Train...')
    #Modelin eğitim detaylarını belirledik
model.fit(x_train, y_train,
          batch_size=batch_size,
          epochs=epochs,
          validation_data=(x_test, y_test))
score, acc = model.evaluate(x_test, y_test, batch_size=batch_size)

    #Test sonucunu yazdırdık
print('Test score:', score)

    #Test işlemindeki doğruluk sonucunu yazdırdık
print('Test accuracy:', acc)
